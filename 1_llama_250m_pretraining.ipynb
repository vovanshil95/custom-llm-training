{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068fc93d-3112-4445-9bf4-a48fb996467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 20:56:14.587132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742061374.611255 3355456 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742061374.616575 3355456 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-15 20:56:14.633978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaConfig\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import LlamaForCausalLM\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd0ed04-35ac-4006-8698-854b7bace718",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in range(torch.cuda.device_count()):\n",
    "    torch.cuda.set_device(device)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526dda7b-cc16-47af-abf6-9c31ac3637df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3ce7cace9b45c6b94bcec39a919c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1b2cb2-0b7f-480a-9ab9-81a88fb41cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvladimirshilonosov2\u001b[0m (\u001b[33mvladimirshilonosov2-itmo\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2307bd3-1c5f-4398-9e21-ebda27ba9a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cd2175327c47c193b999e404edcf7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d6a1f0783b43e0b00f0451ef19d6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"danasone/wikipedia_ru\", split=\"train\")\n",
    "\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(dataset), 1000 * 100):\n",
    "        yield dataset[i : i + 1000][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927c0a1f-20ec-463f-985b-4e5def7f84f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|█████████████████████| 21/21 [00:04<00:00,  5.25it/s]\n",
      "Loading dataset shards: 100%|█████████████████| 21/21 [00:00<00:00, 1482.19it/s]\n",
      "\u001b[2K[00:00:35] Tokenize words                 ██████████████████ 21027394 / 21027394\n",
      "\u001b[2K[00:01:58] Count pairs                    ██████████████████ 21027394 / 21027394\n",
      "\u001b[2K[00:03:22] Compute merges                 ██████████████████ 13414    /    13414\n"
     ]
    }
   ],
   "source": [
    "!python train_tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95d8f94-7b23-469b-9c11-c52c992207e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file='custom_ru_tokenizer.json', eos_token=\"<|endoftext|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b398f4-267a-4dd8-9664-8796d673d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = dataset.shuffle(seed=42).select(range(len(dataset) // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6d5c4d-5ddb-4cb8-b2d3-adb2b0ebcfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Про', 'вед', 'ём', 'те', 'сто', 'вую', 'то', 'ке', 'ни', 'за', 'цию', 'текста', '!']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.tokenize(\"Проведём тестовую токенизацию текста!\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59d0c18-d3af-4fb5-b260-666cc83be159",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = LlamaConfig(\n",
    "    vocab_size=32000,\n",
    "    hidden_size=896,\n",
    "    intermediate_size=3584,\n",
    "    num_hidden_layers=16,\n",
    "    num_attention_heads=16,\n",
    "    num_key_value_heads=8,\n",
    "    max_position_embeddings=2048,\n",
    "    rope_theta=10000.0,\n",
    "    attention_bias=False,\n",
    "    pad_token_id=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ae12c6-7ee5-4dfb-8bc6-73a145b0d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM(custom_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8a27b4-968d-4a5f-ae04-ec3ebccffe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметров модели: 250,049,408\n"
     ]
    }
   ],
   "source": [
    "print(f\"Параметров модели: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a8ac33-792d-440c-9ea9-d5c99658acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 2\n",
      "Input chunk lengths: [425, 155]\n",
      "Chunk mapping: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "context_length = 512\n",
    "\n",
    "outputs = tokenizer(\n",
    "    dataset_sample[:2][\"text\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be055d55-3c5c-4b1f-a60d-0ed2158e40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8beabf53-ed1d-4a28-84f1-b271776ce622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf46f47d5f44379a32c1720ccf1585f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/962693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 924930\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset_sample.map(\n",
    "    tokenize, batched=True, remove_columns=dataset_sample.column_names,\n",
    "    num_proc=16\n",
    ")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9dc799f-0942-46a1-9e11-3801b447e018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 878683\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 46247\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.train_test_split(\n",
    "    test_size=0.05,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c71f5c8-e50f-4f12-9020-51169bdc830c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c9e86516e54c2bb4323ae2d4374db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/878683 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0971667eee534027afcbadc9f76cdf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/46247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk(\"tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a98b9e-2bd8-4729-b251-e22b5d3695ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = load_from_disk('tokenized_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11fff17-752d-49e9-92ca-8bdeaeb8861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8fcee78-4097-4b01-bec3-f3c8d63c2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 512])\n",
      "attention_mask shape: torch.Size([5, 512])\n",
      "labels shape: torch.Size([5, 512])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_dataset['train'][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7440e2e1-2a36-4174-99cd-12bfb635e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-15 20:59:44,241] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshilonosov/miniconda3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/vshilonosov/miniconda3/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"Llama-ru-250M\",\n",
    "    hub_model_id=\"NLPVladimir/Llama-ru-250M\",\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=20,\n",
    "    gradient_accumulation_steps=12,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=200,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    run_name='Llama-ru-250M_pretraining',\n",
    "    report_to=\"wandb\",\n",
    "    optim=\"sgd\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45558446-3cbd-4561-98f1-72660e9a7e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvladimirshilonosov2\u001b[0m (\u001b[33mvladimirshilonosov2-itmo\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/vshilonosov/custom-llm-training/wandb/run-20250315_205946-tckcq4pf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vladimirshilonosov2-itmo/huggingface/runs/tckcq4pf' target=\"_blank\">Llama-ru-250M_pretraining</a></strong> to <a href='https://wandb.ai/vladimirshilonosov2-itmo/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vladimirshilonosov2-itmo/huggingface' target=\"_blank\">https://wandb.ai/vladimirshilonosov2-itmo/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vladimirshilonosov2-itmo/huggingface/runs/tckcq4pf' target=\"_blank\">https://wandb.ai/vladimirshilonosov2-itmo/huggingface/runs/tckcq4pf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshilonosov/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='208' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 208/4068 57:22 < 17:55:13, 0.06 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>126.616100</td>\n",
       "      <td>10.551748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshilonosov/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56714a-27e6-4037-ab81-f2ba6739428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
